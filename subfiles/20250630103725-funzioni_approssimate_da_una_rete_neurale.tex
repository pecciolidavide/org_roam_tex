% Intended LaTeX compiler: pdflatex
\documentclass[../main]{subfiles}


\begin{document}

\begin{definizione}
Sia \((\mathcal{S}, d)\) uno \href{20250301193511-spazio_metrico.org}{spazio metrico} di \href{20250202170607-classe_relazione_binaria.org}{funzioni}. Una \href{20250624155858-neurone_artificiale.org}{rete neurale} è un \uline{approssimatore universale} per \(\mathcal{S}\) se lo spazio \(\mathcal{U}\) delle funzioni output della r.n. è \href{20250301193045-sottoinsieme_denso.org}{denso} in \(\mathcal{S}\).

Lo spazio \(\mathcal{U}\) si dice \uline{spazio di approssimazione} dello \uline{spazio target} \(\mathcal{S}\).
\end{definizione}
\section{Universal Approximation Theorems (Machine Learning)}
\label{sec:orgee144a3}
\subsection{Unidimensionali}
\label{sec:org4dffae2}

\begin{itemize}
\item \href{20250630121612-wiener_s_tauberian_theorems.org}{Applicazioni dei Teoremi Tauberiani di Wiener al Machine Learning}.
\item \href{20250704170145-rete_neurale_che_approssima_funzioni_continue_periodiche.org}{Rete Neurale che approssima funzioni continue periodiche}
\item \href{20250704170145-esistenza_di_una_funzione_continua_approssimabile_da_una_rete_neurale.org}{Esistenza di una funzione continua approssimabile da una rete neurale}
\item \href{20250630154418-one_hidden_layer_perceptron_network_impara_funzioni_continue.org}{One Hidden Layer Perceptron Network impara funzioni continue unidimensionali}
\item \href{20250706121659-one_hidden_layer_sigmoidal_network.org}{One Hidden Layer Sigmoidal Network impara funzioni continue unidimensionali}
\item \href{20250706121659-funzioni_continue_approssimate_lineari_a_tratti.org}{Funzioni continue sono approssimate da funzioni lineari a tratti}
\item \href{20250704170145-one_hidden_layer_relu_network_impara_funzioni_continue_unidimensionali.org}{One Hidden Layer ReLU Network impara funzioni continue unidimensionali}
\item \href{20250704170145-one_hidden_layer_softplus_network_impara_funzioni_continue_unidimensionali.org}{One Hidden Layer softplus Network impara funzioni continue unidimensionali}
\end{itemize}
\subsection{Multidimensionali}
\label{sec:org344978b}

\subsubsection{Funzioni continue}
\label{sec:org3d28810}

\begin{itemize}
\item \href{20250706121659-ohldn_f_continue.org}{One Hidden Layer Discriminatory Network impara funzioni continue sul cubo}
\item \href{20250706121659-ohdspn_fun_cont.org}{One Hidden Layer SigmaPi-Network impara funzioni continue sui compatti}
\end{itemize}
\subsubsection{Funzioni L1}
\label{sec:org8ad59b0}

\begin{itemize}
\item \href{20250706121659-ohldnl1.org}{One Hidden Layer Discriminatory Network impara funzioni L1 sul cubo}
\end{itemize}
\subsubsection{Funzioni L2}
\label{sec:orgf9eabfe}

\begin{itemize}
\item \href{20250706121659-ohldnl2.org}{One Hidden Layer Discriminatory Network impara funzioni L2 sul cubo}
\end{itemize}
\subsubsection{Funzioni Misurabili}
\label{sec:orgfbd247c}

\begin{itemize}
\item \href{20250706121659-ohlsnfmc.org}{One Hidden Layer Sigmoid Network impara funzioni misurabili sui compatti di Rn}
\end{itemize}
\subsubsection{Funzioni Lq}
\label{sec:org4946d14}

\begin{itemize}
\item \href{20250706121659-rnaqi.org}{Reti neurali che approssima funzioni q-integrabili}
\end{itemize}
\end{document}
