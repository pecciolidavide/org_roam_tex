% Created 2026-02-07 Sat 19:34
% Intended LaTeX compiler: pdflatex
\documentclass[10pt]{article}
%% CREATO CON ORG - EMACS
\newcommand{\use}[2][]{\usepackage[#1]{#2}}
% PACCHETTI FONDAMENTLAI
\use[utf8]{inputenc}
\use[T1]{fontenc}
\use{graphicx}
\use{longtable}
\use{wrapfig}
\use{rotating}
\use[normalem]{ulem}
\use{amsmath}
\use{amsthm}
\use{amssymb}

\use{eucal} % Cambia mathcal{...}

\use{capt-of}
\use[italian]{babel}
\use[babel]{csquotes}
% bib la TEX lo carica in automatico org-cite
\use{microtype}
\use{lmodern}
\use{subfig} % sottofigure
\use{multicol} % due colonne
\use{lipsum} % lorem ipsum
\use{color} % colori in latex
\use{parskip} % rimuove l'indentazione dei nuovi paragrafi %% Add parbox=false to all new tcolorbox
\use{centernot}
\use[outline]{contour}\contourlength{3pt}
\use{fancyhdr}
\use{layout}
\use[most]{tcolorbox} % Riquadri colorati
\use{ifthen} % IFTHEN
\use{geometry}

% pacchetti matematica
\use{yhmath}
\use{dsfont}
\use{mathrsfs}
\use{cancel} % semplificare
\use{polynom} %divisione tra polinomi
\use{forest} % grafi ad albero
\use{booktabs} % tabelle
\use{commath} %simboli e differenziali
\use{bm} %bold
\use[fulladjust]{marginnote} %to use marginnote for date notes
\use{arrayjobx}%array
\use[intlimits]{empheq} % Riquadri colorati attorno alle equazioni
\use{mathtools}
\use{circuitikz} % Disegnare i circuiti
\use{mathtools}
\use{stmaryrd} % [[ \llbracket ]] \rrbracket
\use{bussproofs} % dimostrazioni

%%%%%%%%%%%%%


%%%% QUIVER
\newcommand{\duepunti}{\,\mathchar\numexpr"6000+`:\relax\,}
% A TikZ style for curved arrows of a fixed height, due to AndréC.
\tikzset{curve/.style={settings={#1},to path={(\tikztostart)
    .. controls ($(\tikztostart)!\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    and ($(\tikztostart)!1-\pv{pos}!(\tikztotarget)!\pv{height}!270:(\tikztotarget)$)
    .. (\tikztotarget)\tikztonodes}},
    settings/.code={\tikzset{quiver/.cd,#1}
        \def\pv##1{\pgfkeysvalueof{/tikz/quiver/##1}}},
    quiver/.cd,pos/.initial=0.35,height/.initial=0}

% TikZ arrowhead/tail styles.
\tikzset{tail reversed/.code={\pgfsetarrowsstart{tikzcd to}}}
\tikzset{2tail/.code={\pgfsetarrowsstart{Implies[reversed]}}}
\tikzset{2tail reversed/.code={\pgfsetarrowsstart{Implies}}}
% TikZ arrow styles.
\tikzset{no body/.style={/tikz/dash pattern=on 0 off 1mm}}
%%%%%%%%%%


%% DEFINIZIONI COMANDI MATEMATICI
\let\sin\relax %TOGLIE LA DEFINIZIONE SU "\sin"

% cambia la definizione di empty set
% ---
\let\oldemptyset\emptyset
% ---
% \let\emptyset\varnothing
% ---
% \let\emptyset\relax
% \newcommand{\emptyset}{\text{\textnormal{\O}}}
% ---

\DeclareMathOperator{\bounded}{bd}
\DeclareMathOperator{\sin}{sen}
\DeclareMathOperator{\epi}{Epi}
\DeclareMathOperator{\cl}{cl}
\DeclareMathOperator{\graph}{graph}
\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\DeclareMathOperator{\spettro}{Spettro}
\DeclareMathOperator{\nulls}{nullspace}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ar}{ar}
\DeclareMathOperator{\const}{Const}
\DeclareMathOperator{\fun}{Fun}
\DeclareMathOperator{\rel}{Rel}
\DeclareMathOperator{\altezza}{ht}
\let\det\relax %TOGLIE LA DEFINIZIONE SU "\det"
\DeclareMathOperator{\det}{det}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\gl}{GL}
\def\Id{\mathrm{Id}}
\def\id{\mathrm{id}}
\DeclareMathOperator{\I}{\mathds{1}}
\DeclareMathOperator{\II}{II}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\tc}{t.c.}
\DeclareMathOperator{\T}{T}
\DeclareMathOperator{\var}{Var}
\DeclareMathOperator{\cov}{Cov}
\DeclareMathOperator{\st}{st}
\DeclareMathOperator{\mon}{Mon}
\newcommand{\card}[1]{\left\vert #1 \right\vert}
\newcommand{\trasposta}[1]{\prescript{\text{T}}{}{#1}}
\newcommand{\1}{\mathds{1}}
\newcommand{\R}{\mathds{R}}
\newcommand{\diesis}{\#}
\newcommand{\bemolle}{\flat}
\newcommand{\nonstandard}[1]{\prescript{*}{}{#1}}
\newcommand{\starR}{\nonstandard{\R}}
\newcommand{\borel}{\mathscr{B}}
\newcommand{\lebesgue}[1]{\mathscr{L}\left(#1\right)}
\newcommand{\media}{\mathds{E}}
\newcommand{\K}{\mathds{K}}
\newcommand{\A}{\mathds{A}}
\newcommand{\Q}{\mathds{Q}}
\newcommand{\N}{\mathds{N}}
\newcommand{\C}{\mathds{C}}
\newcommand{\Z}{\mathds{Z}}
\newcommand{\qo}{\hspace{1em}\text{q.o.}\,}
\renewcommand{\tilde}[1]{\widetilde{#1}}
\renewcommand{\parallel}{\mathrel{/\mkern-5mu/}}
\newcommand{\parti}[2][]{\wp_{#1}(#2)}
\newcommand{\diff}[1]{\operatorname{d}_{#1}}
\let\oldvec\vec
\renewcommand{\vec}[1]{\overrightarrow{\vphantom{i}#1}}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\cat}[1]{\mathbf{#1}}
\newcommand{\dfreccia}[1]{\xrightarrow{\ #1 \ }}
\newcommand{\sfreccia}[1]{\xleftarrow{\ #1 \ }}
\newcommand{\formalsum}[2]{{\sum_{#1}^{#2}}{\vphantom{\sum}}'}
\newcommand{\minim}[2]{\mu_{#1}\, \left(#2\right)}
\newcommand{\concat}{\null^{\frown}} % concatenazione di stringe
\newcommand{\godelcode}[1]{\langle\!\langle #1 \rangle\!\rangle}
\newcommand{\godeldec}[1]{(\!(#1)\!)}
\newcommand{\termcode}[1]{\ulcorner #1\urcorner}
\newcommand{\partialto}{\dashrightarrow}
\newcommand{\restricted}{\upharpoonright}
\newcommand{\embeds}{\precsim}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\equipotenti}{\asymp}
%% \newcommand{\dotplus}{\mathbin{\dot{+}}} %% A quanto pare esiste già
\newcommand{\bigdot}{\mathbin{\boldsymbol{\cdot}}}
\newcommand{\dotexp}[1]{^{.#1}}
\newcommand{\conv}{\mathbin{*}}
\newcommand{\convolution}[2]{(#1\conv #2)}
\newcommand{\nil}{\mathfrak{N}}
\newcommand{\divisore}{\mathrel{|}}
\newcommand{\simplesso}[1]{\mathrm{e}_{#1}}

\renewcommand{\iff}{\mathrel{\longleftrightarrow}} %% Notazione Logica.
\newcommand{\oldiff}{\mathrel{\Longleftrightarrow}}
\renewcommand{\implies}{\mathrel{\rightarrow}} %% Notazione Logica
\newcommand{\oldimplies}{\mathrel{\Longrightarrow}}
\renewcommand{\impliedby}{\mathrel{\leftarrow}} %% Notazione Logica
\newcommand{\oldimpliedby}{\mathrel{\Longleftarrow}}

\newcommand{\IFF}{\quad\Longleftrightarrow\quad}
\newcommand{\IMPLICA}{\quad\Longrightarrow\quad}


\renewcommand{\descriptionlabel}[1]{\hspace{\labelsep}\normalfont #1} % remove bold from description


%% Definizione di Divergenza di K-L

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
  #1\;\delimsize\|\;#2%
}
\newcommand{\kldiv}{D_{KL}\infdivx}

%% Definizione di \dotminus

\makeatletter
\newcommand{\dotminus}{\mathbin{\text{\@dotminus}}}

\newcommand{\@dotminus}{%
  \ooalign{\hidewidth\raise1ex\hbox{.}\hidewidth\cr$\m@th-$\cr}%
}
\makeatother

%tramite i prossimi due comandi posso decidere come scrivere i logaritmi naturali in tutti i documenti: ho infatti eliminato qualsiasi differenza tra "ln" e "log": se si vuole qualcosa di diverso bisogna inserire manualmente il tutto
\let\ln\relax
\DeclareMathOperator{\ln}{ln}
\let\log\relax
\DeclareMathOperator{\log}{log}
%%%%%%

%% NUOVI COMANDI
\newcommand{\straniero}[1]{\textit{#1}} %parole straniere
\newcommand{\titolo}[1]{\textsc{#1}} %titoli
\newcommand{\qedd}{\tag*{$\blacksquare$}} %qed per ambienti matemastici
\renewcommand{\qedsymbol}{$\blacksquare$} %modifica colore qed
\newcommand{\ooverline}[1]{\overline{\overline{#1}}}
\newcommand{\circoletto}[1]{\left(#1\right)^{\text{o}}}
%
\newcommand{\qmatrice}[1]{\begin{pmatrix}
#1_{11} & \cdots & #1_{1n}\\
\vdots & \ddots & \vdots \\
#1_{m1} & \cdots & #1_{mn}
\end{pmatrix}}
%
\newcommand{\parentesi}[2]{%
\underset{#1}{\underbrace{#2}}%
}
%
\newcommand{\norma}[1]{% Norma
\left\lVert#1\right\rVert%
}
\newcommand{\scalare}[2]{% Scalare
\left\langle #1, #2\right\rangle
}
%%%%%

%% RESTRIZIONI
\newcommand{\referenze}[2]{
        \phantomsection{}#2\textsuperscript{\textcolor{blue}{\textbf{#1}}}
}

\let\restriction\relax

\def\restriction#1#2{\mathchoice
              {\setbox1\hbox{${\displaystyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\textstyle #1}_{\scriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}
              {\setbox1\hbox{${\scriptscriptstyle #1}_{\scriptscriptstyle #2}$}
              \restrictionaux{#1}{#2}}}
\def\restrictionaux#1#2{{#1\,\smash{\vrule height .8\ht1 depth .85\dp1}}_{\,#2}}
%%%%%%%%%%%

%%% FORMATTAZIONE FOOTNOTEMARK

\def\footnotemarkformatting#1{[#1]}
\renewcommand{\thefootnote}{\footnotemarkformatting{\arabic{footnote}}}

%% SEZIONE GRAFICA
\use{tikz}
\usetikzlibrary{matrix, patterns, calc, decorations.pathreplacing, hobby, decorations.markings, decorations.pathmorphing, babel}
\use{tikz-3dplot}
\use{mathrsfs} %per geogebra
\use{tikz-cd}
\tikzset
{
  %surface/.style={fill=black!10, shading=ball,fill opacity=0.4},
  plane/.style={black,pattern=north east lines},
  curve/.style={black,line width=0.5mm},
  dritto/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth}}}, postaction=decorate},
  rovescio/.style={decoration={markings,mark=at position 0.5 with {\arrow{Stealth[reversed]}}}, postaction=decorate}
}
\use{pgfplots} % stampare le funzioni
        \pgfplotsset{/pgf/number format/use comma,compat=1.15}
        %\pgfplotsset{compat=1.15} %per geogebra
        \usepgfplotslibrary{fillbetween, polar}
%%%%%%

%% CITAZIONI
\use{lineno}

\newcommand{\citazione}[1]{%
  \begin{quotation}
  \begin{linenumbers}
  \modulolinenumbers[5]
  \begingroup
  \setlength{\parindent}{0cm}
  \noindent #1
  \endgroup
  \end{linenumbers}
  \end{quotation}\setcounter{linenumber}{1}
  }
%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% AMS THM

\theoremstyle{definition}% default
\newtheorem{thm}{Teorema}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposizione}
\newtheorem{cor}[thm]{Corollario}
\newtheorem{esempio}[thm]{Esempio}
\theoremstyle{plain}
\newtheorem{definizione}[thm]{Definizione}
\theoremstyle{remark}
\newtheorem*{oss}{Osservazione}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\use{hyperref}
\hypersetup{%
        pdfauthor={Davide Peccioli},
        pdfsubject={},
        allcolors=black,
        citecolor=black,
%	colorlinks=true,
        bookmarksopen=true}
\setcounter{secnumdepth}{0} % rimuove i numeri di sezione senza rimuovere le ref
\renewcommand{\href}[2]{\textcolor{blue}{#2}} % disabilita il comando href
\use{enotez} %
\setenotez{%
 mark-format = \footnotemarkformatting % Mette i numeri tra parentesi quadre%
}\let\footnote=\endnote % rende tutte le note a pié pagina come delle note a fine file 


\let\olddocument\document % modifico l'ambiende documenti per non dover stampare \printendnote
\let\oldenddocument\enddocument
\renewenvironment{document}%
{%
  \olddocument
}{%
  \printendnotes\oldenddocument
}
\renewcommand{\thethm}{\arabic{thm}}

\usepackage[hyperref]{biblatex}
\addbibresource{~/Documents/org/roam/bib/master.bib}
\author{Davide Peccioli}
\date{\today}
\title{}
\begin{document}

\section{Gradient Descent con Backpropagation per una RNFF}
\label{sec:org16bbb3b}
Si utilizza la notazione introdotta in ``\href{20250624155858-neurone_artificiale.org}{Rete Neurale Feedforward}'', con input \(x_{i}\) e target \(z_{i}\).

Si supponga di avere una \href{20250624155858-neurone_artificiale.org}{rete neurale} feedforward con parametri \(\bm{w}\), con tutti i neuroni con funzione di attivazione \(\phi\). Si vuole \href{20250627153729-condizioni_necessarie_per_l_esistenza_di_un_minimo_di_una_funzione_reale.org}{minimizzare} la \href{20250624155858-neurone_artificiale.org}{funzione costo} \(C(\bm{w})\), sufficientemente liscia da poter applicare il metodo del \href{20250711122823-algoritmo_di_gradient_descent.org}{Gradient Descent}. È quindi necessario poter calcolare il \href{20250624171244-gradiente_di_una_funzione.org}{gradiente} \(\nabla C\), ovvero calcolare tutte le \href{20250114103236-derivata_parziale.org}{derivate}
\begin{equation*}
\dpd{C}{{w_{ij}^{(\ell)}}}.
\end{equation*}
Si può vedere, allo stesso tempo, \(C\) come una funzione di tutti i segnali \(s_{j}^{(\ell)}\), per \(\ell\) fissato. Inoltre, ciascun \(w_{ij}^{(\ell)}\) influenza, nel layer \(\ell\), soltanto \(s_{j}^{(\ell)}\). Dunque, applicando la chain rule, si ottiene che
\begin{equation*}
\dpd{C}{{w_{ij}^{(\ell)}}} = \dpd{C}{{s^{(\ell)}_{j}}}\cdot \dpd{s^{(\ell)}_{j}}{{w_{ij}^{\ell}}}
\end{equation*}
\begin{itemize}
\item Si denota con \(\delta_{j}^{(\ell)}\coloneqq \pd{C}{{s_{j}^{(\ell)}}}\);
\item Calcolando \(\pd{s^{(\ell)}_{j}}{{w_{ij}^{\ell}}}\), si ottiene
\begin{equation*}
  \pd{s^{(\ell)}_{j}}{{w_{ij}^{\ell}}} = \pd{}{{w_{ij}^{\ell}}}\sum_{k} w_{kj}^{(\ell)} x_{k}^{(\ell-1)} = x_{i}^{(\ell-1)}.
\end{equation*}
\end{itemize}
Segue che ciascun termine del gradiente di \(C\) calcolato rispetto ai pesi \(\bm{w}\) si possa scrivere come
\begin{equation*}
\dpd{C}{{w_{ij}^{(\ell)}}} = x_{i}^{(\ell-1)}\cdot\delta_{j}^{(\ell)}
\end{equation*}

Si vuole trovare i \(\delta_{j}^{(\ell)}\) partendo dal layer più esterno (il Layer \(L\)), e poi calcolare i \(\delta_{j}^{(\ell-1)}\) conoscendo i \(\delta_{j}^{(\ell)}\).
\begin{itemize}
\item Il calcolo degli \(\delta^{(L)}_{j}\) dipende sostanzialmente dalla scelta della funzione costo. Se ad esempio,
\begin{equation*}
C(\bm{w}) = \frac{1}{2}\sum_{h=1}^{d(L)}(x_{h}^{(L)}-z_{h})^{2},
\end{equation*}
allora, dal momento che \(x_{j}^{(L)} = \phi(s_{j}^{L})\), si ottiene che
\begin{equation*}
  \delta_{j}^{(L)} = \dpd{C}{{s_{j}^{L}}} = (x_{j}^{(L)}-z_{j})\,\phi'(s_{j}^{L})
\end{equation*}
\item Si supponga di conoscere i \(\delta^{(\ell)}\).
\begin{align*}
  \delta_{j}^{(\ell-1)} &= \dpd{C}{{s_{j}^{(\ell-1)}}} = \sum_{k} \dpd{C}{{s_{k}^{(\ell)}}}\cdot \dpd{s_{k}^{(\ell)}}{{s_{j}^{(\ell-1)}}}\\
  &= \sum_{k} \dpd{C}{{s_{k}^{(\ell)}}}\cdot \dpd{}{{s_{j}^{(\ell-1)}}}\left[
  \sum_{h}w_{hk}^{(\ell)}\cdot x_{h}^{(\ell-1)}
  \right]\\
  &= \sum_{k} \dpd{C}{{s_{k}^{(\ell)}}}\cdot \dpd{}{{s_{j}^{(\ell-1)}}}\left[
  \sum_{h}w_{hk}^{(\ell)}\cdot \phi(s_{h}^{(\ell-1)})
  \right]\\
  &= \sum_{k} \dpd{C}{{s_{k}^{(\ell)}}}\cdot w_{jk}^{(\ell)}\cdot\phi'(s_{j}^{(\ell-1)})\\
  &= \phi'(s_{j}^{\ell-1}) \cdot\sum_{k} \delta_{k}^{(\ell)}\cdot w_{jk}^{(\ell)}
\end{align*}

Questa è quindi la formula finale:
\begin{equation*}
  \delta_{j}^{(\ell-1)} = \phi'(s_{j}^{\ell-1}) \cdot\sum_{k} \delta_{k}^{(\ell)}\cdot w_{jk}^{(\ell)}.
\end{equation*}
\end{itemize}

Pertanto l'\href{20250711122823-algoritmo_di_gradient_descent.org}{algoritmo di Gradient Descent} con velocità di apprendimento \(\eta\) è
\begin{equation*}
w_{ij}^{(\ell)}(n+1) = w_{ij}^{(\ell)}(n)- \eta\, x_{i}^{(\ell-1)}(n)\cdot\delta_{j}^{(\ell)}(n)
\end{equation*}
\subsection{Problemi con la Backpropagation}
\label{sec:orgcf46f77}

Questo metodo si basa fondamentalmente sulla derivata \(\phi'\) della funzione di attivazione. Questo può portare un errore di \emph{vanishing gradient}, anche per funzioni di attivazioni semplici.

Si consideri infatti \(\phi(t)=\sigma(t)= \frac{1}{1+e^{-t}}\). Se \(t\) è molto grande oppure molto piccolo, allora \(\sigma'(t)\approx 0\). Questo rende il gradiente nullo, e pertanto l'algoritmo non converge (o converge in maniera estremamente lenta).

Inoltre, siccome \(\sigma'=\sigma(1-\sigma)\), si ha che \(\sigma' \in [0,1/4]\), e pertanto la backpropagation attraverso un layer di neuroni riduce il gradiente di \(1/4\). Questo provoca una estrema lentezza di convergenza per l'algoritmo.
\subsection{Inizializzazione dei pesi - Xavier Initialization (Machine Learning)}
\label{sec:org99ca397}
Inizializzare i pesi iniziali \(w_{ij}^{(\ell)}(0) = 0\) causa dei problemi, come mostrato nel seguente esempio.

\begin{esempio}
Si consideri la \href{20250624155858-neurone_artificiale.org}{rete neurale} mostrata in Figura~\ref{fig:retegincuq}, dove \(\phi\) è la \href{20250624155858-neurone_artificiale.org}{funzione logistica} e la funzione costo da minimizzare è la distanza euclidea, e si supponga di eseguire l'algoritmo di cui sopra con i pesi inizializzati a 0.
\begin{align*}
\delta_{1}^{(3)}(0) &= (x^{(3)}_{1}-z_{1})\cdot \phi'(s_{1}^{(3)}(0)) = (x^{(3)}_{1}-z_{1})\cdot\phi'(0)=\frac{1}{2}(x^{(3)}_{1}-z_{1})\\
x_{1}^{(2)} &= \phi(s_{1}^{(2)}) = \phi(0)\\
x_{2}^{(2)} &= \phi(s_{2}^{(2)}) = \phi(0)
\end{align*}
quindi, seguendo l'algoritmo di gradient descent, i pesi \(w_{11}^{(3)}\) e \(w_{21}^{3}\) si aggiornano allo stesso modo. La stessa cosa succede anche per gli altri layer.\qedhere
\label{es:regeoijoijoi}
\end{esempio}

\begin{figure}
\begin{equation*}
\begin{tikzcd}[ampersand replacement=\&,cramped]
	\& \bullet \&\& \bullet \&\& \bullet \\
	\bullet \&\& {\boxed{\Sigma, \phi}} \&\& {\boxed{\Sigma, \phi}} \\
	\&\&\&\&\&\& {\boxed{\Sigma, \phi}} \\
	\bullet \&\& {\boxed{\Sigma, \phi}} \&\& {\boxed{\Sigma, \phi}} \\
	{\ell=0} \&\& {\ell=1} \&\& {\ell=2} \&\& {\ell=L=3}
	\arrow[from=1-2, to=2-3]
	\arrow[from=1-2, to=4-3]
	\arrow[from=1-4, to=2-5]
	\arrow[from=1-4, to=4-5]
	\arrow[from=1-6, to=3-7]
	\arrow[from=2-1, to=2-3]
	\arrow[from=2-1, to=4-3]
	\arrow[from=2-3, to=2-5]
	\arrow[from=2-3, to=4-5]
	\arrow[from=2-5, to=3-7]
	\arrow[from=4-1, to=2-3]
	\arrow[from=4-1, to=4-3]
	\arrow[from=4-3, to=2-5]
	\arrow[from=4-3, to=4-5]
	\arrow[from=4-5, to=3-7]
\end{tikzcd}
\end{equation*}
\caption{\label{fig:retegincuq}Rete neurale per l'Esempio~\ref{es:regeoijoijoi}}
\end{figure}

Si vuole quindi inizializzare i pesi come \href{20250711175937-variabile_aleatoria.org}{variabile aleatoria}, in maniera tale che la varianza degli input e dei \(\delta\) rimanga invariata nella backpropagation attraverso i layer:
\begin{align}
\operatorname{Var}(x^{(\ell)}) &= \operatorname{Var}(x^{(\ell-1)})\label{eq:varianzax}\\
\operatorname{Var}(\delta^{(\ell)}) &= \operatorname{Var}(\delta^{(\ell-1)})\label{eq:deltax}
\end{align}

Si consideri quindi
\begin{align*}
\operatorname{Var}(x_{k}^{(\ell)}) &= \operatorname{Var}(\phi(s_{k}^{(\ell)}))\\
&\underset{1}{= } (\phi'(0))^{2}\operatorname{Var}(s_{k}^{(\ell)}) = \operatorname{Var}(s_{k}^{(\ell)}) =\\
&= \operatorname{Var}\left(\sum_{h} w_{hk}^{(\ell)}\cdot x_{k}^{(\ell-1)}\right) = \sum_{h} \operatorname{Var}( w_{hk}^{(\ell)}\cdot x_{k}^{(\ell-1)}) =\\
&\underset{2}{=} \sum_{h}\operatorname{Var}(w_{hk}^{(\ell)})\cdot \operatorname{Var}(x_{k}^{(\ell-1)}) \underset{3}{=} \sum_{h}\operatorname{Var}(w^{(\ell)})\cdot \operatorname{Var}(x^{(\ell-1)})\\ &= d^{(\ell)}\,\operatorname{Var}(w^{(\ell)})\cdot \operatorname{Var}(x^{(\ell-1)})
\end{align*}
dove si è supposto:
\begin{enumerate}
\item di essere in \uline{regime lineare}, ovvero
\begin{equation*}
 \phi(x)=\phi(0)+\phi'(0)\,x+ o(x^{2});
\end{equation*}
si suppone inoltre che \(\phi'(0)\approx 1\);
\item sotto le opportune ipotesi: \(w^{(\ell)}_{hk}\) e \(x_{k}^{(\ell-1)}\) indipendenti e a media nulla;
\item \(w_{hk}^{(\ell)}\) tutte i.i.d. come \(w^{(\ell)}\) e \(x_{k}^{(\ell-1)}\) tutte i.i.d. come \(x^{(\ell-1)}\).
\end{enumerate}

Dunque affinché~\eqref{eq:varianzax} sia soddisfatta, si deve avere una
\begin{equation}
d^{(\ell)}\operatorname{Var}(w^{(\ell)}) = 1\IMPLICA  \operatorname{Var}(w^{(\ell)}) = \frac{1}{d^{(\ell)}}\label{varianzaell}
\end{equation}

Per quanto riguarda invece i \(\delta\):
\begin{align*}
\operatorname{Var}(\delta_{j}^{(\ell-1)}) &= \operatorname{Var}\left(
\varphi'(s_{j}^{(\ell-1)})\cdot \sum_{k}\delta_{k}^{(\ell)}\cdot w_{jk}^{(\ell)}
\right)\\
&\underset{1}{=} \operatorname{Var}\left(
\sum_{k}\delta_{k}^{(\ell)}\cdot w_{jk}^{(\ell)}
\right) \underset{2}{=} d^{(\ell-1)}\operatorname{Var}(\delta^{(\ell)})\cdot \operatorname{Var}(w^{(\ell)})\\
\end{align*}
dove
\begin{enumerate}
\item continua valere che \(\varphi'(0)\approx 1\), e inoltre \(s_{j}^{(\ell-1)}\approx 0\);
\item sotto le opportune ipotesi: \(\delta^{(\ell)}_{k}\) e \(w_{jk}^{(\ell)}\) indipendenti e a media nulla; \(w_{jk}^{(\ell)}\) tutte i.i.d. come \(w^{(\ell)}\) e \(\delta_{j}^{(\ell)}\) tutte i.i.d. come \(\delta^{(\ell)}\).
\end{enumerate}

Quindi affinché~\eqref{eq:deltax} sia soddisfatta, si deve avere
\begin{equation}
d^{(\ell-1)}\operatorname{Var}(w^{(\ell)})=1\IMPLICA \operatorname{Var}(w^{(\ell-1)}) = \frac{1}{d^{(\ell)}}.\label{varianzaellmenouno}
\end{equation}

La proposta, quindi, è di scegliere come \(\operatorname{Var}(w^{(\ell)})\) la media armonica dei due valori dati dalle Eq.~\eqref{varianzaell} e~\eqref{varianzaellmenouno},
\begin{equation*}
\operatorname{Var}(w^{(\ell)})= \frac{1}{d^{(\ell)} +d^{(\ell-1)}}.
\end{equation*}
\end{document}
